{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 11: Introduction to Deep Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep learning --> differentiable architectures\n",
    "\n",
    "deep learning is feature learning combined with classification tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "The goal of this notebook is to introduce deep neural networks (DNNs) using the high-level Keras package. The reader will become familiar with how to choose an architecture, cost function, and optimizer in Keras. We will also learn how to train neural networks.\n",
    "\n",
    "\n",
    "# MNIST with Keras\n",
    "\n",
    "We will once again work with the MNIST dataset of hand written digits introduced in *Notebook 7: Logistic Regression (MNIST)*. The goal is to find a statistical model which recognizes and distinguishes between the ten handwritten digits (0-9).\n",
    "\n",
    "The MNIST dataset comprises $70000$ handwritten digits, each of which comes in a square image, divided into a $28\\times 28$ pixel grid. Every pixel can take on $256$ nuances of the gray color, interpolating between white and black, and hence each data point assumes any value in the set $\\{0,1,\\dots,255\\}$. Since there are $10$ categories in the problem, corresponding to the ten digits, this problem represents a generic classification task. \n",
    "\n",
    "In this Notebook, we show how to use the Keras python package to tackle the MNIST problem with the help of deep neural networks.\n",
    "\n",
    "The following code is a slight modification of a Keras tutorial, see [https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py). We invite the reader to read Sec. IX of the review to acquire a broad understanding of what the separate parts of the code do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras,sklearn\n",
    "# suppress tensorflow compilation warnings\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "# tf.set_random_seed(seed)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Procedure\n",
    "\n",
    "Constructing a Deep Neural Network to solve ML problems is a multiple-stage process. Quite generally, one can identify the key steps as follows:\n",
    "\n",
    "* ***step 1:*** Load and process the data\n",
    "* ***step 2:*** Define the model and its architecture\n",
    "* ***step 3:*** Choose the optimizer and the cost function\n",
    "* ***step 4:*** Train the model \n",
    "* ***step 5:*** Evaluate the model performance on the *unseen* test data\n",
    "* ***step 6:*** Modify the hyperparameters to optimize performance for the specific data set\n",
    "\n",
    "We would like to emphasize that, while it is always possible to view steps 1-5 as independent of the particular task we are trying to solve, it is only when they are put together in ***step 6*** that the real gain of using Deep Learning is revealed, compared to less sophisticated methods such as the regression models or bagging, described in Secs. VII and VIII of the review. With this remark in mind, we shall focus predominantly on steps 1-5 below. We show how one can use grid search methods to find optimal hyperparameters in ***step 6***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Process the Data\n",
    "\n",
    "Keras can conveniently download the MNIST data from the web. All we need to do is import the `mnist` module and use the `load_data()` class, and it will create the training and test data sets or us.\n",
    "\n",
    "The MNIST set has pre-defined test and training sets, in order to facilitate the comparison of the performance of different models on the data.\n",
    "\n",
    "Once we have loaded the data, we need to format it in the correct shape. This differs from one package to the other and, as we see in the case of Keras, it can even be different depending on the backend used.\n",
    "\n",
    "While choosing the correct `datatype` can help improve the computational speed, we emphasize the rescaling step, which is necessary to avoid large variations in the minimal and maximal possible values of each feature. In other words, we want to make sure a feature is not being over-represented just because it is \"large\".\n",
    "\n",
    "Last, we cast the label vectors $y$ to binary class matrices (a.k.a. one-hot format), as explained in Sec. VII on SoftMax regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an example of a data point with label 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "    \n",
    "# cast floats to single precesion\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[20])\n",
    "plt.matshow(X_train[20,:].reshape(28,28),cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Neural Net and its Architecture\n",
    "\n",
    "We can now move on to construct our deep neural net. We shall use Keras's `Sequential()` class to instantiate a model, and will add different deep layers one by one.\n",
    "\n",
    "At this stage, we refrain from using convolutional layers. This is done further below.\n",
    "\n",
    "Let us create an instance of Keras' `Sequential()` class, called `model`. As the name suggests, this class allows us to build DNNs layer by layer. We use the `add()` method to attach layers to our model. For the purposes of our introductory example, it suffices to focus on `Dense` layers for simplicity. Every `Dense()` layer accepts as its first required argument an integer which specifies the number of neurons. The type of activation function for the layer is defined using the `activation` optional argument, the input of which is the name of the activation function in `string` format. Examples include `relu`, `tanh`, `elu`, `sigmoid`, `softmax`. \n",
    "\n",
    "In order for our DNN to work properly, we have to make sure that the numbers of input and output neurons for each layer match. Therefore, we specify the shape of the input in the first layer of the model explicitly using the optional argument `input_shape=(N_features,)`. The sequential construction of the model then allows Keras to infer the correct input/output dimensions of all hidden layers automatically. Hence, we only need to specify the size of the softmax output layer to match the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_optimizer():\n",
    "    def compile_model(optimizer=keras.optimizers.Adamax()): #Adagrad best at 94.67, epoch 15\n",
    "        # create the mode\n",
    "        model=create_DNN()\n",
    "        # compile the model\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture created successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(1000,input_shape=(img_rows*img_cols,), activation='relu')) #400 is number of neurons; \n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "#     model.add(Dense(200, activation='relu'))\n",
    "\n",
    "#     model.add(Dense(150, activation='relu'))\n",
    "\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the Optimizer and the Cost Function\n",
    "\n",
    "Next, we choose the loss function according to which to train the DNN. For classification problems, this is the cross entropy, and since the output data was cast in categorical form, we choose the `categorical_crossentropy` defined in Keras' `losses` module. Depending on the problem of interest one can pick any other suitable loss function. To optimize the weights of the net, we choose SGD. This algorithm is already available to use under Keras' `optimizers` module, but we could use `Adam()` or any other built-in one as well. The parameters for the optimizer, such as `lr` (learning rate) or `momentum` are passed using the corresponding optional arguments of the `SGD()` function. All available arguments can be found in Keras' online documentation at [https://keras.io/](https://keras.io/). While the loss function and the optimizer are essential for the training procedure, to test the performance of the model one may want to look at a particular `metric` of performance. For instance, in categorical tasks one typically looks at their `accuracy`, which is defined as the percentage of correctly classified data points. To complete the definition of our model, we use the `compile()` method, with optional arguments for the `optimizer`, `loss`, and the validation `metric` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "def compile_model(optimizer=keras.optimizers.Nadam()): #Adagrad best at 94.67, epoch 15\n",
    "    # create the mode\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model\n",
    "\n",
    "We train our DNN in minibatches, the advantages of which were explained in Sec. IV. \n",
    "\n",
    "Shuffling the training data during training improves stability of the model. Thus, we train over a number of training epochs. \n",
    "\n",
    "Training the DNN is a one-liner using the `fit()` method of the `Sequential` class. The first two required arguments are the training input and output data. As optional arguments, we specify the mini-`batch_size`, the number of training `epochs`, and the test or `validation_data`. To monitor the training procedure for every epoch, we set `verbose=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "696/938 [=====================>........] - ETA: 6s - loss: 0.2898 - accuracy: 0.9168"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m model_DNN\u001b[38;5;241m=\u001b[39mcompile_model()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# train DNN and store training info in history\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_DNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64 #break data into baches for stochastic gradient descent\n",
    "epochs = 15\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN=compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history=model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model Performance on the *Unseen* Test Data\n",
    "\n",
    "Next, we evaluate the model and read of the loss on the test data, and its accuracy using the `evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9790\n",
      "\n",
      "Test loss: 0.09125575423240662\n",
      "Test accuracy: 0.9789999723434448\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuxklEQVR4nO3dd3xc9Znv8c8z6r2MZFu2bEsewOAO2MaSaU4WY0MCZEkIGLIbNgklIcmWJMC9IbtJdnO5ublcYJfmELLZULKEsksSA44JpsQ2briBq1ywLAurWL1Lz/3jjKSxGVmjMjqj0fN+vfSaemYejeXznV85vyOqijHGGHM6j9sFGGOMiUwWEMYYY4KygDDGGBOUBYQxxpigLCCMMcYEFet2AcMpJydHCwoK3C7DGGNGjS1btlSqam6wx6IqIAoKCti8ebPbZRhjzKghIkf6esy6mIwxxgRlAWGMMSYoCwhjjDFBRdUYhDHGDFR7ezulpaW0tLS4XUpYJSYmkp+fT1xcXMjbWEAYY8a00tJS0tLSKCgoQETcLicsVJWqqipKS0spLCwMeTvrYjLGjGktLS14vd6oDQcAEcHr9Q64lWQBYYwZ86I5HLoN5ncc8wHR2tHJE2+V8O7+SrdLMcaYiDLmAyLO42Hl2wd5aWup26UYY8agmpoaHn300QFvd9VVV1FTUzP8BQUY8wHh8QiLfF7WlVRhJ08yxoy0vgKis7PzjNutWrWKzMzMMFXlGPMBAVDs81Je18Khyka3SzHGjDH33HMPJSUlzJs3jwULFrBkyRJWrFjB7NmzAbjuuuu48MILmTlzJitXruzZrqCggMrKSg4fPsx5553H1772NWbOnMnSpUtpbm4eltpsmitQ7MsBYF1JFdNyU12uxhjjlh/+7gM+LKsb1tecMTGdf/zszD4fv//++9m1axfbtm1j7dq1XH311ezatatnOupTTz1FdnY2zc3NLFiwgOuvvx6v13vKa+zfv5/nnnuOn//859xwww28+OKL3HLLLUOu3VoQQIE3mbyMRNaXVLldijFmjFu4cOEpxyo8/PDDzJ07l0WLFnH06FH279//iW0KCwuZN28eABdeeCGHDx8ellqsBYEz/avI52Xt3gq6uhSPJ/qnvBljPulM3/RHSkpKSs/1tWvXsmbNGtavX09ycjKXX3550GMZEhISeq7HxMQMWxeTtSD8in05VDe2sffjerdLMcaMIWlpadTXB9/v1NbWkpWVRXJyMnv27GHDhg0jWpu1IPyKfE6f3rqSKs7LS3e5GmPMWOH1elm8eDGzZs0iKSmJ8ePH9zy2bNkyHn/8cebMmcP06dNZtGjRiNYm4ZzaKSLLgIeAGOBJVb3/tMdvBu7232wA7lTV7f7HDgP1QCfQoarz+3u/+fPn61BOGHT5/3mTs8al8uRfLxj0axhjRpfdu3dz3nnnuV3GiAj2u4rIlr72r2FrQYhIDPAIcAVQCmwSkVdU9cOApx0CLlPVkyKyHFgJXBTw+BJVHbFDnIt8Ofx+exkdnV3ExljvmzFmbAvnXnAhcEBVD6pqG/Ab4NrAJ6jqOlU96b+5AcgPYz39KvZ5qW/tYNcwT3MzxpjRKJwBMQk4GnC71H9fX74CvBpwW4HVIrJFRG7rayMRuU1ENovI5oqKiiEVvGha9ziErctkjDHhDIhgc0WDDniIyBKcgLg74O7FqnoBsBz4hohcGmxbVV2pqvNVdX5ubu6QCs5NS2D6+DQ7HsIYYwhvQJQCkwNu5wNlpz9JROYATwLXqmrPnllVy/yXJ4CXcbqswq7I52XT4WpaO868DooxxkS7cAbEJuBsESkUkXjgRuCVwCeIyBTgJeBLqrov4P4UEUnrvg4sBXaFsdYexT4vLe1dbPuoZiTezhhjIlbYAkJVO4C7gNeB3cDzqvqBiNwhInf4n/YDwAs8KiLbRKR7jup44F0R2Q5sBP6gqq+Fq9ZAF03z4hHneAhjjAm3wS73DfDggw/S1NQ0zBX1CutcTlVdparnqKpPVf/Ff9/jqvq4//pXVTVLVef5f+b77z+oqnP9PzO7tx0JGUlxzJqUYeMQxpgREckBYUdSB1Hk8/LUu4doausgOd4+ImNM+AQu933FFVcwbtw4nn/+eVpbW/nc5z7HD3/4QxobG7nhhhsoLS2ls7OT++67j48//piysjKWLFlCTk4Ob7755rDXZnu/IBb7cnjirYNsPnySS88Z2swoY8wo8uo9UL5zeF9zwmxYfn+fDwcu97169WpeeOEFNm7ciKpyzTXX8Pbbb1NRUcHEiRP5wx/+ADhrNGVkZPDAAw/w5ptvkpOTM7w1+9nhwkHML8giLkZsHMIYM6JWr17N6tWrOf/887ngggvYs2cP+/fvZ/bs2axZs4a7776bd955h4yMjBGpx1oQQSTHx3L+5CzW2wFzxowtZ/imPxJUlXvvvZfbb7/9E49t2bKFVatWce+997J06VJ+8IMfhL0ea0H0ocjnZeexWmqb290uxRgTxQKX+77yyit56qmnaGhoAODYsWOcOHGCsrIykpOTueWWW/jOd77D1q1bP7FtOFgLog/FPi8PvbGfjYequWLG+P43MMaYQQhc7nv58uWsWLGCoqIiAFJTU3n66ac5cOAA3/3ud/F4PMTFxfHYY48BcNttt7F8+XLy8vLCMkgd1uW+R9pQl/sO1NrRydwfruamhVMi4ixTxpjwsOW++17u27qY+pAQG8OCgmw7HsIYM2ZZQJxBkc/LnvJ6Khta3S7FGGNGnAXEGRT7nLnFGw5aK8KYaBZNXe19GczvaAFxBrMmppOWEGvHQxgTxRITE6mqqorqkFBVqqqqSExMHNB2NovpDGJjPFw0zcYhjIlm+fn5lJaWMtQTjkW6xMRE8vMHdtJOC4h+FPlyWLP7BGU1zUzMTHK7HGPMMIuLi6OwsNDtMiKSdTH1o9jnnIbUWhHGmLHGAqIf08enkZ0Sb+MQxpgxxwKiHx6PUDTNy/qSyqgexDLGmNNZQISgyOelrLaFI1XhOzGHMcZEGguIEHSPQ1g3kzFmLLGACEFhTgoT0hNZZ8t/G2PGEAuIEIgIxT4v60ui+2AaY4wJZAERoiKfl6rGNvZ93OB2KcYYMyIsIEJU1DMOYd1MxpixwQIiRPlZyUz1JttAtTFmzLCAGIBin5cNB6vo7LJxCGNM9LOAGIAiXw71LR18UFbrdinGGBN2FhADUDTNjocwxowdFhADkJuWwDnjUy0gjDFjggXEABX7cth0qJq2ji63SzHGmLCygBigIp+X5vZOtpfWuF2KMcaElQXEAC0q9CIC6w5YN5MxJrpZQAxQRnIcsyZm2AFzxpioZwExCMU+L+9/VENzW6fbpRhjTNhYQAxCkc9LW2cXW46cdLsUY4wJm7AGhIgsE5G9InJARO4J8vjNIrLD/7NOROaGuq2bFhRkE+sR62YyxkS1sAWEiMQAjwDLgRnATSIy47SnHQIuU9U5wI+BlQPY1jUpCbHMm5xpx0MYY6JaOFsQC4EDqnpQVduA3wDXBj5BVdepanc/zQYgP9Rt3Vbs87KjtIa6lna3SzHGmLAIZ0BMAo4G3C7139eXrwCvDnRbEblNRDaLyOaKioohlDswRb4cuhQ2Hqwesfc0xpiRFM6AkCD3BV0GVUSW4ATE3QPdVlVXqup8VZ2fm5s7qEIH4/wpmSTEeqybyRgTtWLD+NqlwOSA2/lA2elPEpE5wJPAclWtGsi2bkqMi2F+QZYNVBtjolY4WxCbgLNFpFBE4oEbgVcCnyAiU4CXgC+p6r6BbBsJin057Cmvp6qh1e1SjDFm2IUtIFS1A7gLeB3YDTyvqh+IyB0icof/aT8AvMCjIrJNRDafadtw1TpY3ach3WDjEMaYKBTOLiZUdRWw6rT7Hg+4/lXgq6FuG2nmTMogNSGWdSWVXD0nz+1yjDFmWNmR1EMQG+NhYWE2622g2hgThSwghqjY5+VgZSPHa5vdLsUYY4aVBcQQdY9DWCvCGBNtLCCG6LwJ6WQlx9nxEMaYqGMBMUQej1Dk87K+pArVoMfyGWPMqGQBMQyKfDkcq2nmo+omt0sxxphhYwExDIr94xDWzWSMiSYWEMNgWk4K49MTLCCMMVHFAmIYiAjFvhzWl1TaOIQxJmpYQAyTIp+XyoY29p9ocLsUY4wZFhYQw6RnHOKAre5qjIkOFhDDJD8rmSnZyTYOYYyJGhYQw6jY52XDwSo6u2wcwhgz+llADKMin5e6lg4+LKtzuxRjjBkyC4hhVNRzPISNQxhjRj8LiGE0Li2Rs8el2jiEMSYq9BsQIvJTEUkXkTgReUNEKkXklpEobjQq9nnZdLiato4ut0sxxpghCaUFsVRV64DPAKXAOcB3w1rVKFbky6GprZMdpTVul2KMMUMSSkDE+S+vAp5TVTsB8xksmpaNiK3LZIwZ/UIJiN+JyB5gPvCGiOQCLeEta/TKTI5n5sR0G6g2xox6/QaEqt4DFAHzVbUdaASuDXdho1mxL4etR2poae90uxRjjBm0UAapvwB0qGqniHwfeBqYGPbKRrEin5e2zi62HDnpdinGGDNooXQx3aeq9SJyMXAl8CvgsfCWNbotKMgm1iPWzWSMGdVCCYjufpKrgcdU9b+B+PCVNPqlJsQyd3KmDVQbY0a1UALimIg8AdwArBKRhBC3G9OKfV52lNZS39LudinGGDMooezobwBeB5apag2QjR0H0a8in5fOLmXTYZsVbIwZnUKZxdQElABXishdwDhVXR32yka5C6ZkER/rYd0B62YyxoxOocxi+jbwDDDO//O0iHwz3IWNdolxMcyfmmXjEMaYUSuULqavABep6g9U9QfAIuBr4S0rOhT7vHx4vI6TjW1ul2KMMQMWSkAIvTOZ8F+X8JQTXYp8OQBsOGitCGPM6BMbwnN+CbwnIi/7b18H/CJsFUWROfkZpMTHsK6kiuWz89wuxxhjBqTfgFDVB0RkLXAxTsvhVlV9P9yFRYO4GA8LC7PtgDljzKjUZ0CISHbAzcP+n57HbFXX0BT7cnhz724+rmthfHqi2+UYY0zIzjQGsQXY7L/svr454Hq/RGSZiOwVkQMick+Qx88VkfUi0ioi3zntscMislNEtolISO8XibpPQ7reZjMZY0aZPlsQqlo4lBcWkRjgEeAKnBMNbRKRV1T1w4CnVQPfwhnXCGaJqo7q/pkZeelkJMWxrqSS686f5HY5xhgTsnAumbEQOKCqB1W1DfgNpy0TrqonVHUTELXrUXg8QtE0rx0PYYwZdcIZEJOAowG3S/33hUqB1SKyRURu6+tJInKbiGwWkc0VFRWDLDW8is/yUnqymaPVTW6XYowxIQtnQAQ7VkIHsP1iVb0AWA58Q0QuDfYkVV2pqvNVdX5ubu5g6gy7Yv84hM1mMsaMJn0GhIhkn+knhNcuBSYH3M4HykItTFXL/JcngJdxuqxGJV9uKrlpCdbNZIwZVc50HMQWnG/8fbUEpvXz2puAs0WkEDgG3AisCKUoEUkBPP4TFaUAS4EfhbJtJBIRin3OOISqImIHohtjIl/YZjGpaod/9dfXgRjgKVX9QETu8D/+uIhMwJkymw50icjfAjOAHOBl/440FnhWVV8bSj1uK/Z5+e9tZZRUNHDWuDS3yzHGmH71eyS1OHvpm4FCVf2xiEwBJqjqxv62VdVVwKrT7ns84Ho5TtfT6eqAuf29/mhS7F+XaV1JlQWEMWZUCGWQ+lGgiN7uoXqc4xvMAEzOTiY/K8nOD2GMGTVCCYiLVPUbQAuAqp7Ezkk9KMU+L+sPVtHVNZDJXMYY445QAqLdf1S0AohILtAV1qqiVLEvh9rmdj48Xud2KcYY069QAuJhnGmm40TkX4B3gZ+EtaooZesyGWNGk1DOSf0M8D3gfwHHgetU9bfhLiwajU9P5KxxqXbAnDFmVAh1ue8TwHOBj9ly34NT7PPy4pZS2ju7iIsJ54HsxhgzNKEu910B7AP2+69vCX9p0anY56WxrZMdpbVul2KMMWfUZ0CoaqGqTsM50O2zqpqjql7gM8BLI1VgtLmo0IsIrLduJmNMhAulj2OB/4A3AFT1VeCy8JUU3bJS4pmRl27rMhljIl4oAVEpIt8XkQIRmSoi/xOwvdsQFPu8bD5ykpb2TrdLMcaYPoUSEDcBuThTXf8LGOe/zwxSsS+Hto4uth456XYpxhjTp37XYvLPVvq2iKQDXaraEP6yotuCwmxiPMK6kiqKz8pxuxxjjAmq3xaEiMwWkfeBncAH/jO8zQp/adErNSGWufkZdjyEMSaihdLF9ATw96o6VVWnAv8ArAxvWdGv2JfD9tJaGlo73C7FGGOCCiUgUlT1ze4bqroWSAlbRWNEsc9LZ5ey6ZAdb2iMiUyhBMRBEbnPP4upQES+DxwKd2HR7oKpWcTHeqybyRgTsUIJiL/BmcX0Es5Mplzg1nAWNRYkxsVw4ZQsOx7CGBOxQpnFdBL41gjUMuYU+7w8sGYfJxvbyEqxU2wYYyJLKLOY5ovISyKyVUR2dP+MRHHRrvgsL6rw3iFrRRhjIk+/LQjgGeC7ONNc7URBw2hOfibJ8TGsK6li2aw8t8sxxphThBIQFar6StgrGYPiYjwsLMy2cQhjTEQKZZD6H0XkSRG5SUT+svsn7JWNEcU+LwdONHCirsXtUowx5hShtCBuBc4F4ujtYlJsye9hUexzltpYf7CKa+dNcrkaY4zpFUpAzFXV2WGvZIw6Ly+djKQ41h2wgDDGRJZQupg2iMiMsFcyRsV4hEXTsll30A6YM8ZEllAC4mJgm4js9U9x3WnTXIdXsS+Ho9XNHK1ucrsUY4zpEUoX07KwVzHGFfu8AKwvqWJydrLL1RgTwVRhyy/hnQfgwi/D4m9DTJzbVUWtflsQqnok2M9IFDdWnDUulZzUBFuXyZgzaaqG/7wFfv93IB74049h5eVQusXtyqJWKF1MJsxEhGKfl3UlVaiq2+UYE3kOvQ2PLYZ9r8PSf4ZvbYMbn4WmKvjFX8Br90KrnctsuFlARIhin5cT9a2UVNgfuTE9OtthzQ/hV9dAfDJ8dQ0UfxM8Hjj3avjGe3DhrbDhUXi0CPb/0e2Ko4oFRIS45JxcYj3C15/ZykELCWOgqgR+sRTefQAu+BLc/jZMnHfqcxIz4DMPwK2vQVwiPPN5ePGr0FDhSsnRxgIiQkzKTOLfb11IZUMb1/7bn1n9QbnbJRnjDlXY9iw8cSlUl8AXfgXX/CvEn+E8ZVOL4I534bJ74IP/gkcWOK9hXbZDYgERQS4+O4ffffNiCnNTuO3XW/jpa3vo7LI/cDOGNNfAi1+B/7oT8ubCnetg5nWhbRubAEvuhTveAe/Zzmv8+jqotvObDVZYA0JElvmPnzggIvcEefxcEVkvIq0i8p2BbButJmUm8fztRdy4YDKPri3hy7/cSHVjm9tlGRN+H70Hj1/itAA+9X34699BRv7AX2fcefA3r8NVP3NmOD1aBH9+GDrt/O8DFbaAEJEY4BFgOTADuCnIEdnVOCcj+tkgto1aiXEx3H/9HO7/y9m8d6iaz/7ru+wsrXW7LGPCo7MD1v5v+OUyEHF27pd+Fzwxg39NjwcWfs0ZxJ52OfzxPnjyU1C2bbiqHhPC2YJYCBxQ1YOq2gb8Brg28AmqekJVNwHtA912LLhx4RReuKMIgOsfX8fzm466XJExw6zmI/jVZ2DtT2DW551xhMkLhu/1MybBTc/BF/4d6o7Dzz8Fq++DNlu1IBThDIhJQOAerdR/37BuKyK3ichmEdlcUTHImQtr/gm2/LszayLCBrXm5Gfyu29ezMKCbL734g7ufWknrR2dbpdlzNDtegkeuxjKd8HnVsL1P4fE9OF/HxGY+Tm4ayPMWwHrHobHiqDkzeF/rygTylIbgyVB7gt17xvytqq6ElgJMH/+/IHv3dtbYPtvoP64czs9HwovgYJLnMvMKQN+yeGWnRLPr/5mIT9bvZfH1pbwYVktj91yIRMzk9wuzZiBa22AV++GbU/DpPlw/ZOQXRj+903Kgmv/DeZ8EX73bWcAe+4KuPJfIDk7/O8/CoUzIEqByQG384GyEdh2YOIS4e93Q+V+OPw2HHrHOdhm+3PO45lT/YFxqXOZPjEsZfQnxiPcvexc5uZn8p3fbucz//ou/3bT+RSfleNKPcYMyrGtznEK1QedcYbL7h75tZQKL4E7/wxv/dRpTexfDcv/N8y63mltmB4SrqUdRCQW2Ad8GjgGbAJWqOoHQZ77T0CDqv5soNsGmj9/vm7evHnoxXd1QcUeOPyOc4j/4XehpcZ5LNvX28IouATSxg/9/QaopKKBO369hZKKBr637Fxuv3QaYn/YJpJ1dTk74z/9GFLHw1+uhIKL3a7K6d565ZtQthXOXgpXPwCZk/vfLoqIyBZVnR/0sXCu/SMiVwEPAjHAU6r6LyJyB4CqPi4iE4DNQDrO2eoagBmqWhds2/7eb9gC4nRdXfDxTqd1cfgdOLIOWuucx3KmnxoYKd7hf/8gGls7+N4LO/jDzuMsnzWB//OFuaQmhLNBaMwg1R2Hl2+HQ2/BedfAZx+KrC6drk547wn40z87tz99Hyy8bWizqEYR1wJipIUtIE7X2QHl2wMCYz20NzqPjZsZEBiLnX7PMFFVnnznEPe/tocCbzJPfOlCzhqXFrb3G3aqzgqddaVQewzq/D/d18EZXJz9+bB+jiaM9qyC//4GdLTAsvvhgr+K3G6cmo/g938PB/4Iky50jt4eP9PtqsLOAiLcOtuh7H1/d9Q7zgE/Hc2AwITZUHipExhTi5y1Y4bZ+pIq7np2Ky3tnfzsC3NZPjtv2N9jwFSh+eSpO/zTr9eVOTuOQJ44SM+D9EnQUgsnPoSYeGdhtnk3w7QlEGMtpYjX3gyrvw+bnoQJc+D6X0DuOW5X1T9V2PkCvHa38/e3+Ntw6fecscpIpjro4LWAGGkdrXBsS28L4+hG6Gx11rDPm9c76D1lESSkDstbHq9t5s6nt7LtaA23XzqN7145ndiYMM1iVnX+89SV+Xf6pb07/MDr7afNNZcYSMtz5qanT3IG/DPynevd96WMcw5y6n6f8h3Omjo7nofmakidAHO/6IRF7vTw/H6RpqvL+RzEA7nnQmy82xWdWfkuZ7mMij1QdBd8+gfOMhijSWMVrP6fzmSVbB9c87D7YybtzXDyCJw8DCcPOZfV/ksR56DAQbCAcFt7C5Ru7A2M0s3Q1Q6eWJh4QW+X1OSLnCWNB6m1o5Mf//5Dnt7wEcXTsnn4pnnkpCTQM0NY9bTrBH+ss83pN64r9e/0j512/Ri0nbbirHicnXeGf8efnv/J66njB9+v29HqnAtg27POrBPtdLoB5q1wZp9EWxdUWyMcXAt7X3V+34aPnftj4p1uj7y5/p95MG5GZHzDVYWNK50D0RIz4HOPw1mfdruqoSn5E/zub6HmiNM9dsWPwve3pgqNFafu+LuD4OTh3qn43eJTIavA+fGeBVf8cFBvawERadoa4eh7vYFxbKuzw5MYZwfQ3w79TDv3sBBIHRfwTT/f/+0/4HrahJGbrthwwmlRbHvG3wWV0NsF5VsyegcXa0th32uw9zWnu7KzFRIynJ3sOcuc3+v4dv/PNqcVB84XjdzzYKI/MPLmwvhZQ/qyMWANFfDfX3fC7Owr4dpHIDV35N4/nNoaYe3/gvWPQEouLP8pzLh2cF06Ha1Qc/TUHX91wPXuscxu6ZN6QyCrsPd6diEke4dlPMcCItK11sNHG5yuqO4+eRF6jhfs+SOQMz8WcP1EfQu/21FOQ2snS6bnMjs/0z8VVgIOQ+zjNTyxTldQ+kTnDzQtLzK7NVSdneW2Z2Hn886YR1qecyDUvJsjv8+7qwuOv+8Ewr5XoXync39WIUxf7oTC1OLgwavqfKs9vt1ZX6g7NJqqnMfF48ywy5vrnEMhb64zHpYQhkkMB9bAy3c6gbX0n501kCJ1IHooyt6HV77ldPdNvxqu/tknj4vqHnurPhQQAoecrqHqQ/7JFwH73NikU3f6gWGQOWVEWoYWEGPUycY2vv2f23h7XwU3zM/nR9fOIjFulH677k9Hq/Pte9uzzoGO2gn5C5wuqJl/CUmZblfoaGuEg285gbDvdafrSDwweRFMX+aEQs45g9vBqjo7oJ5Whj88GrrPLSJOV8QpoTFn8J9NRyu88SNY/29OC+bzv4j+WT+dHbDhEXjzJ86EiqKv+8cGDvf+dE+B75Y6PngLIKvAeczlMLWAGMM6u5SH1uzj4T8dYNakdB67+UImZ49g14Mb6j92WhTvPwMVu50uqPM+44TFNBe6oGqPOeG1z9911NECCen+rqPlcPYV4T0uoL4cju9wWhjdwVEbsNRZVmHvmMbEeTBhbv/H81Tsgxf/xmn1LPgaLP0xxI2hpV+qDzpjE4fecrqFM6d+sgWQVQBZU898oqMIYAFhWPPhx/zd89uI8QgP33g+l54TJf3DZ6Lq7BS3PQs7f9vbBTX3RmcNnnB1QXV1Oe+77zVnkLl8h3N/VoETCNOXwZRid7vtGitPHc84vt359tstY3LvIHh3eKSNdz7Trb+CV+9xAuG6R53usLGo+ziepKzemXejkAWEAeBQZSN3/HoL+07U852l07nzMh8eTxT2FQfTZxfUzc7BeEPtgmprcr5N7u3uOip3uo7yF/q7jpY703IjuW+++aTTIugZ09gOVQfo6TNPy3MmKxzf7pxj4brHnWNWzKhmAWF6NLV1cM+LO3llexlXzBjP/71hLumJI7xYmtvqy3tnQVXsgdhEOLe7C+ry0Lug6sr8XUevO1NSO1ogPs3pOpq+HM66YsSWXgmb1nonNLoDo2KvE6hFd43qb82mlwWEOYWq8ss/H+Ynq3YzOTuZx2+5kOkTRtESHcNF1ZmZ0t0F1VIDaROdLqh5KyDn7E8+//i23llHx7c792dODZh1tDgyZ3wZ0wcLCBPUxkPVfP2ZrTS2dvDTz8/hs3PdWco8InS0Ot1D25511uLRLqd7aN4K5xiP7pZC/fHerqNzrnSCIffcyO46MuYMLCBMnz6ua+Hrz2xly5GTfOXiQu5Zfi5x4VqiY7SoL4cd/+mERcUe5774NDjrU/5ZR0tHf9eRMX4WEOaM2jq6+Mmq3fz7usMsLMzmkRUXkJs2ytbOCYfuLqjWephSZF1HJiqdKSDG+FdFAxAf6+GfrpnJ//viXHaU1nD1w+/w3MaPaOvocrs0d4nApAtg2mUWDmZMsoAwPT53fj4v3bmYvIxE7n1pJ0t+tpZn37OgMGassi4m8wmqytp9FTy0Zj/bjtYwKTOJry/x8YULJxMfa98pjIkmNgZhBkVVeXt/JQ+u2cf7H9UwMSORO5ecxQ3z80mIjdI1nYwZYywgzJCoKu/4g2LrRzXkZSTy9ct93LBgsgWFMaOcBYQZFqrKuwcqeWjNfjYfOcmE9ETuvNzHFxdMjt5VYo2JchYQZlipKutKqnhwzT42HT7J+PQE7rzMx40Lp1hQGDPKWECYsFBV1pdU8eAb+9l4qJpxaQnccZmPFRdZUBgzWlhAmLBb729RvHeomlx/UNxsQWFMxLOAMCNmw8EqHlqzn/UHq8hJTeCOy6Zx80VTSYq3oDAmEllAmBH33sEqHnpjP+tKnKC4/dJp3LxoCsnxsW6XZowJYAFhXLPxUDUPvbGPPx+oIic1ntsuncYti6ZaUBgTISwgjOs2H67moTf2887+Srwp8Xzt0ml8adFUUhIsKIxxkwWEiRhbjlTz4BonKLJT4vnaJdP4qyILCmPcYgFhIs6WIyd5+I39vLWvgqzkOL56yTT+uriAVAsKY0aUBYSJWO9/dJKH3tjP2r0VZCbH9bQo0sbaebKNcYkFhIl4247W8NCafby5t4KMpDi+enEhX15cYEFhTJhZQJhRY/vRGh5+Yz9v7DmBCGQnx5OTmkBOmv+y5yeenLQEcv23vanxdqpUYwbhTAFhHb4mosydnMkvvryAnaW1/HH3x1Q2tFJZ30plQyvvf1RDZUMrTW2dQbfNTI7rDQ9/cOSmnXo7x3/bVqE1pn9hDQgRWQY8BMQAT6rq/ac9Lv7HrwKagC+r6lb/Y4eBeqAT6Ogr4Ux0mp2fwez8jKCPNbV1UFnfRkWDExxOiLT1Xm9o5YOyOirrW6lv7Qj6GmmJsT2tj/5aJ3YUuBmrwhYQIhIDPAJcAZQCm0TkFVX9MOBpy4Gz/T8XAY/5L7stUdXKcNVoRqfk+FimeGOZ4k3u97kt7Z3+0GjraYl0367wt072ltfz54Yqapvbg77GpMwkls2awPJZE7hgShYejwz3r2RMRApnC2IhcEBVDwKIyG+Aa4HAgLgW+A91BkI2iEimiOSp6vEw1mXGkMS4GPKzksnP6j9M2jq6qGrsbY1UNLRSUd/K1iMn+fX6I/zi3UOMS0tg2awJLJs1gYUF2cTauIeJYuEMiEnA0YDbpZzaOujrOZOA44ACq0VEgSdUdWUYazWG+FgPeRlJ5GUkfeKx+pZ2/rTnBK/uLOf5zUf5j/VHyE6J58qZ41k2K49in9cGyU3UCWdABGuHnz5l6kzPWayqZSIyDvijiOxR1bc/8SYitwG3AUyZMmUo9RrTp7TEOK6dN4lr502iqa2Dt/ZWsGpXOa9sK+O5jUdJT4zlihlON9TFZ+fYMucmKoQzIEqByQG384GyUJ+jqt2XJ0TkZZwuq08EhL9lsRKcaa7DVbwxfUmOj2X57DyWz86jpb2Td/dXsmrXcf74YTkvbi0lNSGWT507juWzJnDZ9FxbmNCMWuH8y90EnC0ihcAx4EZgxWnPeQW4yz8+cRFQq6rHRSQF8Khqvf/6UuBHYazVmEFJjIvhL2aM5y9mjKeto4v1B6t4dedxVn/4Ma9sLyMxzsOS6eNYNmsCnzp3nB34Z0aVsAWEqnaIyF3A6zjTXJ9S1Q9E5A7/448Dq3CmuB7AmeZ6q3/z8cDLzixYYoFnVfW1cNVqzHCIj/Vw2Tm5XHZOLv98XRcbD1fz6s5yXv+gnFd3lRMf4+HSc3JYNiuPK84bT0ayhYWJbHYktTFh1tWlbP3oJK/uKufVnccpq20h1iMU+bxcNTuPpTPG401NcLtMM0bZUhvGRAhVZUdprRMWu45zpKoJj8DCwmyump3HlTMnMD490e0yzRhiAWFMBFJVdh+v57Vdx1m1q5wDJxoQgQumZLHcf6xFKMdvGDMUFhDGjAIHTtTz6s5yVu0qZ/fxOgDm5GewfFYey2dNoCAnxeUKTTSygDBmlDlc2chrHzhjFttLawFIT4wlMzmerOQ4MpPjyUyOIys5noykuE/cl+m/nZYQa0uDmDOygDBmFDtW08zqD8o5UtXEyaY2apraqWlq46T/sq4l+IKEAB7BCY6kuN5A6Q6RpDgyU5zL3lBxrifHx+CfRWiinC33bcwoNikziVsXF/b5eEdnF3UtHaeER01Te+/tZidMapvaKa9rYU95PTVNbTT2sWw6QFyM9ARLb6g416d6U5g+IY3pE9LsFLFRzv51jRnlYmM8ZKfEk50SP6DtWjs6qW1u94eKEyi13cHS7G+lNDoBc7S6iZ2l7VQ3tdHW0dXzGpOzk5g+Pp1z/YFx7oQ0CnNSbBHDKGEBYcwYlRAbw7i0GMalhT6ttqtLOVbTzJ7yevaW17GnvJ495fW8ufcEnV1Od3V8jAffuNSe0OgOjgnpidZtNcpYQBhjQubxCJOzk5mcncwVM8b33N/a0cmBEw3sLa9nrz801pdU8fL7x3qek5EU1xMW3ZfnjE+z5UcimAWEMWbIEmJjmDkxg5kTTz0LYE1TmxMaH9f7Wx31vLT1GA0BZ/qblJl0WmsjnWm5Ka4sn97VpdS3dlDX3E5tc3vPZW1zO3Ut3fd19NzX2tFJdko83hTnvOje1ARy/ZfeFOcyPTF21LacLCCMMWGTmRzPRdO8XDTN23OfqlJ6svm04KjjrX0VdPi7qeJiBF9udzdV7xhHXkb/3VRtHV1Bduq9O/u6lg5qm059vPs59a0dnGliZ4xHSE+MJSMpjvSkOBJiPewtr6eqsYqapuBnJIyP8fjDozdIcvwBkpMacDvVGUeKpPOl2zRXY0xEaO3o5GBFY08XVfcYx/Halp7npCfGMn1CGtNyUmnv/GQQ1Da309LedYZ3gcQ4D+mJcWQkxfXs6HuuJ8b23O65TIwjI9m5nnKG6b/tnV2cbGyjsqHNOTNhQytVDf7bDa1UNTqX3ae7DRzsD5SeGNsTGIGBknNayyQn1TkGZqitEzsOwhgzatU2tbP3497A2Ftez+GqRhLjYk7b0cd+Yqefnhhw3f94JHxDV1Ua2zp7AiPwsqqxrSdcnKBp42RTW9CWTaxH8KbGMyU7md/eUTyoWuw4CGPMqJWRHMfCwmwWFma7XcqwERFSE2JJTYhlqrf/JVQ6Ors42dROVWN3qyQgUBraCNcQhwWEMcZEuNgYD7lpCeSmjeyy8HY0izHGmKAsIIwxxgRlAWGMMSYoCwhjjDFBWUAYY4wJygLCGGNMUBYQxhhjgrKAMMYYE1RULbUhIhXAkUFungNUDmM5o5l9Fqeyz+NU9nn0iobPYqqq5gZ7IKoCYihEZHNf65GMNfZZnMo+j1PZ59Er2j8L62IyxhgTlAWEMcaYoCwgeq10u4AIYp/FqezzOJV9Hr2i+rOwMQhjjDFBWQvCGGNMUBYQxhhjghrzASEiy0Rkr4gcEJF73K7HTSIyWUTeFJHdIvKBiHzb7ZrcJiIxIvK+iPze7VrcJiKZIvKCiOzx/40UuV2Tm0Tk7/z/T3aJyHMikuh2TcNtTAeEiMQAjwDLgRnATSIyw92qXNUB/IOqngcsAr4xxj8PgG8Du90uIkI8BLymqucCcxnDn4uITAK+BcxX1VlADHCju1UNvzEdEMBC4ICqHlTVNuA3wLUu1+QaVT2uqlv91+txdgCT3K3KPSKSD1wNPOl2LW4TkXTgUuAXAKrapqo1rhblvlggSURigWSgzOV6ht1YD4hJwNGA26WM4R1iIBEpAM4H3nO5FDc9CHwP6HK5jkgwDagAfunvcntSRFLcLsotqnoM+BnwEXAcqFXV1e5WNfzGekBIkPvG/LxfEUkFXgT+VlXr3K7HDSLyGeCEqm5xu5YIEQtcADymqucDjcCYHbMTkSyc3oZCYCKQIiK3uFvV8BvrAVEKTA64nU8UNhMHQkTicMLhGVV9ye16XLQYuEZEDuN0PX5KRJ52tyRXlQKlqtrdonwBJzDGqr8ADqlqhaq2Ay8BxS7XNOzGekBsAs4WkUIRiccZZHrF5ZpcIyKC08e8W1UfcLseN6nqvaqar6oFOH8Xf1LVqPuGGCpVLQeOish0/12fBj50sSS3fQQsEpFk//+bTxOFg/axbhfgJlXtEJG7gNdxZiE8paofuFyWmxYDXwJ2isg2/33/Q1VXuVeSiSDfBJ7xf5k6CNzqcj2uUdX3ROQFYCvO7L/3icJlN2ypDWOMMUGN9S4mY4wxfbCAMMYYE5QFhDHGmKAsIIwxxgRlAWGMMSYoCwhjIoCIXG4rxppIYwFhjDEmKAsIYwZARG4RkY0isk1EnvCfL6JBRP6viGwVkTdEJNf/3HkiskFEdojIy/71exCRs0RkjYhs92/j8798asD5Fp7xH6FrjGssIIwJkYicB3wRWKyq84BO4GYgBdiqqhcAbwH/6N/kP4C7VXUOsDPg/meAR1R1Ls76Pcf9958P/C3OuUmm4RzZboxrxvRSG8YM0KeBC4FN/i/3ScAJnOXA/9P/nKeBl0QkA8hU1bf89/8K+K2IpAGTVPVlAFVtAfC/3kZVLfXf3gYUAO+G/bcypg8WEMaEToBfqeq9p9wpct9pzzvT+jVn6jZqDbjeif3/NC6zLiZjQvcG8HkRGQcgItkiMhXn/9Hn/c9ZAbyrqrXASRG5xH//l4C3/OfXKBWR6/yvkSAiySP5SxgTKvuGYkyIVPVDEfk+sFpEPEA78A2ck+fMFJEtQC3OOAXAXwOP+wMgcPXTLwFPiMiP/K/xhRH8NYwJma3maswQiUiDqqa6XYcxw826mIwxxgRlLQhjjDFBWQvCGGNMUBYQxhhjgrKAMMYYE5QFhDHGmKAsIIwxxgT1/wGYFGk+TbFR+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 6: Modify the Hyperparameters to Optimize Performance of the Model\n",
    "\n",
    "Last, we show how to use the grid search option of scikit-learn to optimize the \n",
    "hyperparameters of our model. An excellent blog on this by Jason Brownlee can be found on [https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apaar\\AppData\\Local\\Temp\\ipykernel_6048\\2585860508.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model_gridsearch = KerasClassifier(build_fn=compile_model,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 6s 8ms/step - loss: 0.9601 - accuracy: 0.7340\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4553 - accuracy: 0.8848\n",
      "704/704 [==============================] - 7s 8ms/step - loss: 0.9715 - accuracy: 0.7340\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4490 - accuracy: 0.8829\n",
      "704/704 [==============================] - 6s 8ms/step - loss: 0.9886 - accuracy: 0.7226\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8759\n",
      "704/704 [==============================] - 6s 7ms/step - loss: 0.9899 - accuracy: 0.7284\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.4395 - accuracy: 0.8881\n",
      "704/704 [==============================] - 10s 13ms/step - loss: 0.2626 - accuracy: 0.9212\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1295 - accuracy: 0.9605\n",
      "704/704 [==============================] - 9s 12ms/step - loss: 0.2641 - accuracy: 0.9202\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1328 - accuracy: 0.9564\n",
      "704/704 [==============================] - 11s 15ms/step - loss: 0.2603 - accuracy: 0.9196\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1371 - accuracy: 0.9571\n",
      "704/704 [==============================] - 10s 13ms/step - loss: 0.2603 - accuracy: 0.9196\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1169 - accuracy: 0.9661\n",
      "704/704 [==============================] - 8s 10ms/step - loss: 1.5743 - accuracy: 0.5596\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.9485 - accuracy: 0.8185\n",
      "704/704 [==============================] - 9s 11ms/step - loss: 1.5927 - accuracy: 0.5664\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.9864 - accuracy: 0.8070\n",
      "704/704 [==============================] - 10s 13ms/step - loss: 1.6084 - accuracy: 0.5462\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.9998 - accuracy: 0.7989\n",
      "704/704 [==============================] - 9s 11ms/step - loss: 1.5856 - accuracy: 0.5630\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.9347 - accuracy: 0.8343\n",
      "704/704 [==============================] - 12s 16ms/step - loss: 2.2630 - accuracy: 0.1520\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 2.1475 - accuracy: 0.3415\n",
      "704/704 [==============================] - 16s 22ms/step - loss: 2.2697 - accuracy: 0.1576\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.1645 - accuracy: 0.3395\n",
      "704/704 [==============================] - 15s 20ms/step - loss: 2.3080 - accuracy: 0.1286\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.1959 - accuracy: 0.1973\n",
      "704/704 [==============================] - 14s 18ms/step - loss: 2.2857 - accuracy: 0.1365\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.1602 - accuracy: 0.2485\n",
      "704/704 [==============================] - 11s 15ms/step - loss: 0.2581 - accuracy: 0.9216\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1250 - accuracy: 0.9621\n",
      "704/704 [==============================] - 12s 15ms/step - loss: 0.2576 - accuracy: 0.9216\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1154 - accuracy: 0.9649\n",
      "704/704 [==============================] - 12s 16ms/step - loss: 0.2600 - accuracy: 0.9226\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9590\n",
      "704/704 [==============================] - 13s 17ms/step - loss: 0.2600 - accuracy: 0.9207\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1306 - accuracy: 0.9593\n",
      "704/704 [==============================] - 12s 16ms/step - loss: 0.3427 - accuracy: 0.8994\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9487\n",
      "704/704 [==============================] - 13s 16ms/step - loss: 0.3445 - accuracy: 0.8986\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9505\n",
      "704/704 [==============================] - 10s 13ms/step - loss: 0.3427 - accuracy: 0.9011\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1795 - accuracy: 0.9487\n",
      "704/704 [==============================] - 10s 13ms/step - loss: 0.3544 - accuracy: 0.8984\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1734 - accuracy: 0.9491\n",
      "704/704 [==============================] - 11s 14ms/step - loss: 0.2581 - accuracy: 0.9234\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1275 - accuracy: 0.9615\n",
      "704/704 [==============================] - 15s 19ms/step - loss: 0.2561 - accuracy: 0.9240\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.9643\n",
      "704/704 [==============================] - 13s 17ms/step - loss: 0.2588 - accuracy: 0.9228\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9620\n",
      "704/704 [==============================] - 13s 16ms/step - loss: 0.2587 - accuracy: 0.9226\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1273 - accuracy: 0.9616\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.2295 - accuracy: 0.9312\n",
      "Best: 0.962367 using {'optimizer': 'Nadam'}\n",
      "0.882933 (0.004439) with: {'optimizer': 'SGD'}\n",
      "0.960017 (0.003829) with: {'optimizer': 'RMSprop'}\n",
      "0.814683 (0.013300) with: {'optimizer': 'Adagrad'}\n",
      "0.281733 (0.061527) with: {'optimizer': 'Adadelta'}\n",
      "0.961317 (0.002370) with: {'optimizer': 'Adam'}\n",
      "0.949267 (0.000753) with: {'optimizer': 'Adamax'}\n",
      "0.962367 (0.001149) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# call Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn=compile_model, \n",
    "                        epochs=1, \n",
    "                        batch_size=batch_size, \n",
    "                        verbose=1)\n",
    "\n",
    "# list of allowed optional arguments for the optimizer, see `compile_model()`\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# define parameter dictionary\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "# call scikit grid search module\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=1, cv=4)\n",
    "grid_result = grid.fit(X_train,Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Convolutional Neural Nets with Keras\n",
    "\n",
    "We have so far considered each MNIST data sample as a $(28\\times 28,)$-long 1d vector. This approach neglects any spatial structure in the image. On the other hand, we do know that in every one of the hand-written digits there are *local* spatial correlations between the pixels, which we would like to take advantage of to improve the accuracy of our classification model. To this end, we first need to reshape the training and test input data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can ask the question of whether a neural net can learn to recognize such local patterns. As we saw in Sec. X of the review, this can be achieved by using convolutional layers. Luckily, all we need to do is change the architecture of our DNN, i.e. introduce small changes to the function `create_model()`. We can also merge **Step 2** and **Step 3** for convenience: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # flatten data\n",
    "    model.add(Flatten())\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(20*4*4, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the deep conv net (**Step 4**) and evaluating its performance (**Step 6**) proceeds exactly as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 19ms/step - loss: 0.2703 - accuracy: 0.9149 - val_loss: 0.0910 - val_accuracy: 0.9769\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1008 - accuracy: 0.9686 - val_loss: 0.0583 - val_accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.0752 - accuracy: 0.9772 - val_loss: 0.0452 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.0401 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.0343 - val_accuracy: 0.9903\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.0468 - accuracy: 0.9857 - val_loss: 0.0287 - val_accuracy: 0.9923\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.0334 - val_accuracy: 0.9905\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0301 - val_accuracy: 0.9921\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 753s 804ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.0263 - val_accuracy: 0.9935\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0263 - accuracy: 0.9935\n",
      "\n",
      "Test loss: 0.026332242414355278\n",
      "Test accuracy: 0.9934999942779541\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
